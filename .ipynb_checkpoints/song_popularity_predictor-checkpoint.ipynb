{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43bf222-32a6-4cc7-8722-7a7f13f6cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81356266-5f81-410a-a0a9-999c35f9e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e697e740-cbd8-499c-b44c-533d262ec1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  spotify_data.zip\n",
      "  inflating: dataset/spotify_top_songs_audio_features.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip spotify_data.zip -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee43dbc6-48a7-465d-8da1-0df5d39313b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35486524-b110-45fb-bbcb-159729bd3869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>artist_names</th>\n",
       "      <th>track_name</th>\n",
       "      <th>source</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>weeks_on_chart</th>\n",
       "      <th>streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000xQL6tZNLJzIrtIgxqSl</td>\n",
       "      <td>ZAYN, PARTYNEXTDOOR</td>\n",
       "      <td>Still Got Time (feat. PARTYNEXTDOOR)</td>\n",
       "      <td>RCA Records Label</td>\n",
       "      <td>G</td>\n",
       "      <td>Major</td>\n",
       "      <td>4 beats</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.13100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.524</td>\n",
       "      <td>-6.029</td>\n",
       "      <td>120.963</td>\n",
       "      <td>188491</td>\n",
       "      <td>17</td>\n",
       "      <td>107527761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003eoIwxETJujVWmNFMoZy</td>\n",
       "      <td>Alessia Cara</td>\n",
       "      <td>Growing Pains</td>\n",
       "      <td>Def Jam Recordings</td>\n",
       "      <td>C#/Db</td>\n",
       "      <td>Minor</td>\n",
       "      <td>4 beats</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.08220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-6.276</td>\n",
       "      <td>191.153</td>\n",
       "      <td>193680</td>\n",
       "      <td>2</td>\n",
       "      <td>9944865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003vvx7Niy0yvhvHt4a68B</td>\n",
       "      <td>The Killers</td>\n",
       "      <td>Mr. Brightside</td>\n",
       "      <td>Island Records</td>\n",
       "      <td>C#/Db</td>\n",
       "      <td>Major</td>\n",
       "      <td>4 beats</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-5.230</td>\n",
       "      <td>148.033</td>\n",
       "      <td>222973</td>\n",
       "      <td>125</td>\n",
       "      <td>512388123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00B7TZ0Xawar6NZ00JFomN</td>\n",
       "      <td>Cardi B, Chance the Rapper</td>\n",
       "      <td>Best Life (feat. Chance The Rapper)</td>\n",
       "      <td>Atlantic/KSR</td>\n",
       "      <td>A</td>\n",
       "      <td>Major</td>\n",
       "      <td>4 beats</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>0.28700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.665</td>\n",
       "      <td>-7.438</td>\n",
       "      <td>167.911</td>\n",
       "      <td>284856</td>\n",
       "      <td>2</td>\n",
       "      <td>11985346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00Blm7zeNqgYLPtW6zg8cj</td>\n",
       "      <td>Post Malone, The Weeknd</td>\n",
       "      <td>One Right Now (with The Weeknd)</td>\n",
       "      <td>Republic Records</td>\n",
       "      <td>C#/Db</td>\n",
       "      <td>Major</td>\n",
       "      <td>4 beats</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.03610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.688</td>\n",
       "      <td>-4.806</td>\n",
       "      <td>97.014</td>\n",
       "      <td>193507</td>\n",
       "      <td>30</td>\n",
       "      <td>301860377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                artist_names  \\\n",
       "0  000xQL6tZNLJzIrtIgxqSl         ZAYN, PARTYNEXTDOOR   \n",
       "1  003eoIwxETJujVWmNFMoZy                Alessia Cara   \n",
       "2  003vvx7Niy0yvhvHt4a68B                 The Killers   \n",
       "3  00B7TZ0Xawar6NZ00JFomN  Cardi B, Chance the Rapper   \n",
       "4  00Blm7zeNqgYLPtW6zg8cj     Post Malone, The Weeknd   \n",
       "\n",
       "                             track_name              source    key   mode  \\\n",
       "0  Still Got Time (feat. PARTYNEXTDOOR)   RCA Records Label      G  Major   \n",
       "1                         Growing Pains  Def Jam Recordings  C#/Db  Minor   \n",
       "2                        Mr. Brightside      Island Records  C#/Db  Major   \n",
       "3   Best Life (feat. Chance The Rapper)        Atlantic/KSR      A  Major   \n",
       "4       One Right Now (with The Weeknd)    Republic Records  C#/Db  Major   \n",
       "\n",
       "  time_signature  danceability  energy  speechiness  acousticness  \\\n",
       "0        4 beats         0.748   0.627       0.0639       0.13100   \n",
       "1        4 beats         0.353   0.755       0.7330       0.08220   \n",
       "2        4 beats         0.352   0.911       0.0747       0.00121   \n",
       "3        4 beats         0.620   0.625       0.5530       0.28700   \n",
       "4        4 beats         0.687   0.781       0.0530       0.03610   \n",
       "\n",
       "   instrumentalness  liveness  valence  loudness    tempo  duration_ms  \\\n",
       "0               0.0    0.0852    0.524    -6.029  120.963       188491   \n",
       "1               0.0    0.3900    0.437    -6.276  191.153       193680   \n",
       "2               0.0    0.0995    0.236    -5.230  148.033       222973   \n",
       "3               0.0    0.3140    0.665    -7.438  167.911       284856   \n",
       "4               0.0    0.0755    0.688    -4.806   97.014       193507   \n",
       "\n",
       "   weeks_on_chart    streams  \n",
       "0              17  107527761  \n",
       "1               2    9944865  \n",
       "2             125  512388123  \n",
       "3               2   11985346  \n",
       "4              30  301860377  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/spotify_top_songs_audio_features.csv')\n",
    "# Convert to a NumPy array, optionally selecting only numeric columns\n",
    "array = df.select_dtypes(include=[float, int, object]).to_numpy()\n",
    "df.head() #we want to preview the df before converting into numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e785bc94-9e8c-4d2f-b772-0e9cef365810",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_all_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c53e898-4b08-4d67-a90d-bdcd587e54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and validation\n",
    "split_ratio = 0.9\n",
    "# Shuffle the array if necessary\n",
    "np.random.shuffle(numpy_all_data)  # Uncomment this line if you want to shuffle the array\n",
    "split_index = int(len(numpy_all_data) * split_ratio)\n",
    "\n",
    "train_data = numpy_all_data[:split_index]\n",
    "validation_data = numpy_all_data[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a807c062-b2a0-41ea-b020-320d71ba569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111359\n"
     ]
    }
   ],
   "source": [
    "print(train_data.size) #This is the data set we will be using to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1837784b-eb73-40ac-87f2-5486ab56a5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12388\n"
     ]
    }
   ],
   "source": [
    "print(validation_data.size) #This is the data set we will use to determine the performance of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5fc10c6-00a9-470c-bfee-bd79c6016572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to split the columns into feature columns and target columns- this is going to be a regression task\n",
    "features_training = train_data[:,7:-1]\n",
    "target_training = train_data[:,-1]\n",
    "\n",
    "features_validation = validation_data[:,7:-1]\n",
    "target_validation = validation_data[:,-1]\n",
    "\n",
    "#convert the dtype of the numpy to valid float to avoid issues when converting to tensor\n",
    "\n",
    "features_training_numeric = features_training.astype(float)\n",
    "target_training_numeric = target_training.astype(float)\n",
    "\n",
    "features_validation_numeric = features_validation.astype(float)\n",
    "target_validation_numeric = target_validation.astype(float)\n",
    "\n",
    "X = torch.from_numpy(features_training_numeric).float() \n",
    "\n",
    "#convert to tensors\n",
    "features_tensor_training = torch.tensor(features_training_numeric, dtype=torch.float32)\n",
    "target_tensor_training = torch.tensor(target_training_numeric, dtype=torch.float32)\n",
    "#these tensors will be used in the validation of the model\n",
    "features_tensor_validation = torch.tensor(features_validation_numeric, dtype=torch.float32)\n",
    "target_tensor_validation = torch.tensor(target_validation_numeric, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d1821a74-5c7f-4dc6-944d-6ed1d184d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.3700e-01,  7.9900e-01,  3.3800e-02,  3.9400e-01,  0.0000e+00,\n",
      "         9.2100e-02,  5.6200e-01, -4.5190e+00,  1.0500e+02,  2.2862e+05,\n",
      "         1.0000e+00])\n",
      "tensor([5032951.])\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorDataset\n",
    "spotify_tensor_dataset = TensorDataset(features_tensor_training, target_tensor_training.view(-1, 1))  # Ensuring target tensor is the correct shape\n",
    "\n",
    "train,target = spotify_tensor_dataset[0]\n",
    "print(train)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83fdc073-6010-4020-964a-4bdc4ec998e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset stores the samples and their corresponding labels \n",
    "\n",
    "batch_size = 4\n",
    "#DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "regression_train_loader = DataLoader(spotify_tensor_dataset, batch_size = batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f27a4cb3-1efc-4e09-9651-fe17652c2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model that we are going to use\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SongPopularityPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, dropout_rate):\n",
    "        super(SongPopularityPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_size2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85eebd60-6186-41ee-89d5-d07a8d541a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 10175729631232.0\n",
      "Epoch [2/200], Loss: 18437610930176.0\n",
      "Epoch [3/200], Loss: 2.6685657448238285e+17\n",
      "Epoch [4/200], Loss: 2426686318575616.0\n",
      "Epoch [5/200], Loss: 7861851199111168.0\n",
      "Epoch [6/200], Loss: 8767638863872000.0\n",
      "Epoch [7/200], Loss: 1.0583931141226496e+16\n",
      "Epoch [8/200], Loss: 3287043161456640.0\n",
      "Epoch [9/200], Loss: 5404445932257280.0\n",
      "Epoch [10/200], Loss: 2222580882735104.0\n",
      "Epoch [11/200], Loss: 161050519404544.0\n",
      "Epoch [12/200], Loss: 7348036208427008.0\n",
      "Epoch [13/200], Loss: 2639870241538048.0\n",
      "Epoch [14/200], Loss: 2490240828702720.0\n",
      "Epoch [15/200], Loss: 4473941536014336.0\n",
      "Epoch [16/200], Loss: 6166264682643456.0\n",
      "Epoch [17/200], Loss: 5420396903923712.0\n",
      "Epoch [18/200], Loss: 2527422092148736.0\n",
      "Epoch [19/200], Loss: 8026250736041984.0\n",
      "Epoch [20/200], Loss: 9537377533952000.0\n",
      "Epoch [21/200], Loss: 325392963469312.0\n",
      "Epoch [22/200], Loss: 4166380270125056.0\n",
      "Epoch [23/200], Loss: 4164972863029248.0\n",
      "Epoch [24/200], Loss: 2184459021451264.0\n",
      "Epoch [25/200], Loss: 7.58257062856622e+16\n",
      "Epoch [26/200], Loss: 219156762853376.0\n",
      "Epoch [27/200], Loss: 7522199816634368.0\n",
      "Epoch [28/200], Loss: 3579395411279872.0\n",
      "Epoch [29/200], Loss: 2.7905740404424704e+16\n",
      "Epoch [30/200], Loss: 5958667975262208.0\n",
      "Epoch [31/200], Loss: 7875778704310272.0\n",
      "Epoch [32/200], Loss: 2428398668349440.0\n",
      "Epoch [33/200], Loss: 1612525472841728.0\n",
      "Epoch [34/200], Loss: 5.51413714213929e+16\n",
      "Epoch [35/200], Loss: 1.0183062516137984e+16\n",
      "Epoch [36/200], Loss: 1044866289106944.0\n",
      "Epoch [37/200], Loss: 9738027668602880.0\n",
      "Epoch [38/200], Loss: 934798356905984.0\n",
      "Epoch [39/200], Loss: 995899769618432.0\n",
      "Epoch [40/200], Loss: 1.165665935294464e+16\n",
      "Epoch [41/200], Loss: 1.1065574142509056e+16\n",
      "Epoch [42/200], Loss: 8899009028554752.0\n",
      "Epoch [43/200], Loss: 6501492248805376.0\n",
      "Epoch [44/200], Loss: 178377172451328.0\n",
      "Epoch [45/200], Loss: 1.6298623499239424e+16\n",
      "Epoch [46/200], Loss: 5.535832739938304e+16\n",
      "Epoch [47/200], Loss: 3.4633355272545894e+17\n",
      "Epoch [48/200], Loss: 5592718508032000.0\n",
      "Epoch [49/200], Loss: 8.44263782959022e+16\n",
      "Epoch [50/200], Loss: 4109258815700992.0\n",
      "Epoch [51/200], Loss: 86698000121856.0\n",
      "Epoch [52/200], Loss: 2317820977217536.0\n",
      "Epoch [53/200], Loss: 8582498392997888.0\n",
      "Epoch [54/200], Loss: 1.1886099727122432e+16\n",
      "Epoch [55/200], Loss: 1.1670657725104128e+16\n",
      "Epoch [56/200], Loss: 618911699566592.0\n",
      "Epoch [57/200], Loss: 3694472885960704.0\n",
      "Epoch [58/200], Loss: 3.0291068603858944e+16\n",
      "Epoch [59/200], Loss: 4451903253512192.0\n",
      "Epoch [60/200], Loss: 8057495012507648.0\n",
      "Epoch [61/200], Loss: 5980359707590656.0\n",
      "Epoch [62/200], Loss: 6730053765300224.0\n",
      "Epoch [63/200], Loss: 2.257113547223859e+16\n",
      "Epoch [64/200], Loss: 9804041315942400.0\n",
      "Epoch [65/200], Loss: 548736262471680.0\n",
      "Epoch [66/200], Loss: 4486665913499648.0\n",
      "Epoch [67/200], Loss: 7490939970912256.0\n",
      "Epoch [68/200], Loss: 3541118662737920.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[103], line 22\u001b[0m, in \u001b[0;36mSongPopularityPredictor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[0;32m---> 22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(x)\n\u001b[1;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Initialize the model instance, also include the loss function, we will use Mean Squared Loss since this a regression task\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming your input features have 11 dimensions\n",
    "input_size = 11\n",
    "hidden_size1 = 64\n",
    "hidden_size2 = 32\n",
    "dropout_rate = 0.2\n",
    "\n",
    "model = SongPopularityPredictor(input_size, hidden_size1, hidden_size2, dropout_rate)\n",
    "outputs = model(X)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#Run training loop for our model\n",
    "# Assuming model, criterion (loss function), and optimizer are defined\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in regression_train_loader:\n",
    "        model.train()\n",
    "        model.eval()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print or log the loss for monitoring\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf092c-f9aa-4441-825d-359473ed7ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
